now we can use the updated proof to update the database. but we need more tests to be sure that this works.


when we calculate the precomputed multi exponent in verify2:update, it seems like we are putting a bunch of zeros in unnecessarily.


in verify2:update_batch2, when we calculate the precomputed multi exponent, it is crashing.
the format must be wrong somehow.



we need code for calculating the new state root after updating some elements in a verkle proof.

* make a SNARK of a verkle proof.


we want to store all the different sized things in a single tree.



which parts could be re-written in c to make it fast.

* for storage. store:pme2 + secp256k1:me3. We want to pass in a list of points, and have it add them all up fast.
 - pme2 accepts a matrix as input, it is looking up points from a precompute, and then summing them all. the precompute is powers of the generator points.
 - me3 is alternatively adding, and then (doubling the accumulated amount 8 times).

* for proving. multiproof:calc_G_e. it is important not to list the entire As, it has a lot of repetitions. Have a compact non-repeating list of As, and a seperate list of pointers to show which of these corresponds to which Zs/Y combination. parameters:div_e can be made shorter if we are willing to do a few extra finite field multiplications. This will be a good investment because then the parameters fit into the L1 cache.
involves a polynomial addition, multiplying the polynomials by scalars, multiplying precompute vectors together.

* for verifying: secp256k1:multi_exponent. The bucket method. involves adding up lots of generator points, then doing me3.
  - we specifically want to implement the calculation of Ss. this is very similar to pme2 from storage, but instead of looking up precomputed powers of generator points, we do that in step bucketify2/4

libraries we need in a fast language:

* group order polynomials
  - vector addition.
  - vector multiplied by scalar.
  - div_e, looking up constants and lots of multiplication.


we can make inner product arguments around 2x faster by using the same pre-compute strategy that we use for storage. Store powers of the base point, so we can skip that step of the bucket strategy.


maybe stems should store their data as lists, because in store.erl we only access the data in order.
This could potentially make storage about 1 second faster.
but it looks like it would make it slower to look up data.

there are a couple todo notes in store.erl

